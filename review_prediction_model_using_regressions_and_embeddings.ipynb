{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2c50831e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import (\n",
        "    r2_score,\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_percentage_error,\n",
        ")\n",
        "\n",
        "from config import (\n",
        "    RANDOM_STATE,\n",
        "    CSV_FILEPATH_MODEL_READY_DATA,\n",
        "    EMBEDEDINGS_FILEPATH_Mini_LML6_v2,\n",
        "    EMBEDEDINGS_FILEPATH_mpnet_base_v2,\n",
        "    EMBEDEDINGS_FILEPATH_open_ai_api,\n",
        "    EMBEDEDINGS_FILEPATH_tf_idf_bigrams,\n",
        "    EMBEDEDINGS_FILEPATH_tf_idf_monograms,\n",
        "    load_embeddings_and_data,\n",
        ")\n",
        "\n",
        "TARGET_COL = \"points\"\n",
        "TEST_SIZE = 0.2\n",
        "IS_FIRST_COLUMN_INDEX = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12b643e2",
      "metadata": {},
      "source": [
        "# Embeddings catalog\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4a26d43a",
      "metadata": {},
      "outputs": [],
      "source": [
        "EMBEDDING_SOURCES = {\n",
        "    \"MiniLM-L6-v2\": EMBEDEDINGS_FILEPATH_Mini_LML6_v2,\n",
        "    \"mpnet-base-v2\": EMBEDEDINGS_FILEPATH_mpnet_base_v2,\n",
        "    \"OpenAI-API\": EMBEDEDINGS_FILEPATH_open_ai_api,\n",
        "    \"TF-IDF bigrams\": EMBEDEDINGS_FILEPATH_tf_idf_bigrams,\n",
        "    \"TF-IDF monograms\": EMBEDEDINGS_FILEPATH_tf_idf_monograms,\n",
        "}\n",
        "\n",
        "embedding_order_all = list(EMBEDDING_SOURCES.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0420794",
      "metadata": {},
      "source": [
        "# Data loading helper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3f9ad777",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_embedding_dataset(embedding_path, csv_path=CSV_FILEPATH_MODEL_READY_DATA):\n",
        "    # CSV_FILEPATH_MODEL_READY_DATA has no explicit index column\n",
        "    return load_embeddings_and_data(\n",
        "        embeddings_filepath=embedding_path,\n",
        "        csv_filepath=csv_path,\n",
        "        isFirstColumnIndex=IS_FIRST_COLUMN_INDEX,\n",
        "        check_length=True,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a484bf4",
      "metadata": {},
      "source": [
        "# Feature preparation (preserve vintage nulls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d7323590",
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_features(df, target_col=TARGET_COL, vintage_col=\"vintage\"):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Preserve information about missing vintage values\n",
        "    if vintage_col in df.columns:\n",
        "        df[\"vintage_missing\"] = df[vintage_col].isna().astype(int)\n",
        "\n",
        "    y = df[target_col]\n",
        "    X = df.drop(columns=[target_col])\n",
        "\n",
        "    # Keep numeric features only (all model-ready features are numeric)\n",
        "    X = X.select_dtypes(include=\"number\")\n",
        "\n",
        "    # Embedding columns are integers (0..N-1) after concatenation\n",
        "    base_cols = [c for c in X.columns if not isinstance(c, int)]\n",
        "    emb_cols = [c for c in X.columns if isinstance(c, int)]\n",
        "\n",
        "    # sklearn requires uniform (string) feature names\n",
        "    X.columns = X.columns.astype(str)\n",
        "    base_cols = [str(c) for c in base_cols]\n",
        "    emb_cols = [str(c) for c in emb_cols]\n",
        "\n",
        "    return X, y, base_cols, emb_cols\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dd9624d",
      "metadata": {},
      "source": [
        "# Preprocessing pipelines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "60abc046",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_preprocessor_all_features():\n",
        "    return Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ])\n",
        "\n",
        "\n",
        "def build_preprocessor_with_polynomial(base_cols, emb_cols, degree=2):\n",
        "    # Apply polynomial only to base features to keep feature count manageable\n",
        "    transformers = []\n",
        "\n",
        "    if base_cols:\n",
        "        base_pipeline = Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
        "            (\"scaler\", StandardScaler()),\n",
        "        ])\n",
        "        transformers.append((\"base\", base_pipeline, base_cols))\n",
        "\n",
        "    if emb_cols:\n",
        "        emb_pipeline = Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"scaler\", StandardScaler()),\n",
        "        ])\n",
        "        transformers.append((\"emb\", emb_pipeline, emb_cols))\n",
        "\n",
        "    return ColumnTransformer(transformers, remainder=\"drop\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d7745ea",
      "metadata": {},
      "source": [
        "# Regression models catalog\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "240d46d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_regression_builders():\n",
        "    return {\n",
        "        \"Linear\": lambda base_cols, emb_cols: Pipeline([\n",
        "            (\"preprocess\", build_preprocessor_all_features()),\n",
        "            (\"model\", LinearRegression()),\n",
        "        ]),\n",
        "        \"Ridge\": lambda base_cols, emb_cols: Pipeline([\n",
        "            (\"preprocess\", build_preprocessor_all_features()),\n",
        "            (\"model\", Ridge(alpha=1.0)),\n",
        "        ]),\n",
        "        \"Lasso\": lambda base_cols, emb_cols: Pipeline([\n",
        "            (\"preprocess\", build_preprocessor_all_features()),\n",
        "            (\"model\", Lasso(alpha=0.001, max_iter=10000, random_state=RANDOM_STATE)),\n",
        "        ]),\n",
        "        \"ElasticNet\": lambda base_cols, emb_cols: Pipeline([\n",
        "            (\"preprocess\", build_preprocessor_all_features()),\n",
        "            (\"model\", ElasticNet(alpha=0.001, l1_ratio=0.5, max_iter=10000, random_state=RANDOM_STATE)),\n",
        "        ]),\n",
        "        \"PolynomialRidge(deg2)\": lambda base_cols, emb_cols: Pipeline([\n",
        "            (\"preprocess\", build_preprocessor_with_polynomial(base_cols, emb_cols, degree=2)),\n",
        "            (\"model\", Ridge(alpha=1.0)),\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "regression_builders = get_regression_builders()\n",
        "regression_order_all = list(regression_builders.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a6f3d81",
      "metadata": {},
      "source": [
        "## Experiment selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "15f3d451",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose a subset (None = all)\n",
        "ACTIVE_EMBEDDINGS = None  # e.g. [\"MiniLM-L6-v2\", \"TF-IDF bigrams\"]\n",
        "ACTIVE_REGRESSIONS = None  # e.g. [\"Linear\", \"Ridge\"]\n",
        "SHOW_PROGRESS = True\n",
        "\n",
        "\n",
        "def select_dict_subset(source_dict, active_keys):\n",
        "    if active_keys is None:\n",
        "        return source_dict\n",
        "    missing = [k for k in active_keys if k not in source_dict]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing keys: {missing}\")\n",
        "    return {k: source_dict[k] for k in active_keys}\n",
        "\n",
        "\n",
        "EMBEDDING_SOURCES_ACTIVE = select_dict_subset(EMBEDDING_SOURCES, ACTIVE_EMBEDDINGS)\n",
        "regression_builders_active = select_dict_subset(regression_builders, ACTIVE_REGRESSIONS)\n",
        "\n",
        "embedding_order = list(EMBEDDING_SOURCES_ACTIVE.keys())\n",
        "regression_order = list(regression_builders_active.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3641473",
      "metadata": {},
      "source": [
        "To add new embeddings, extend `EMBEDDING_SOURCES`.\n",
        "To add new regressions, extend `get_regression_builders()` with a new entry.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90febdc9",
      "metadata": {},
      "source": [
        "# Metrics and evaluation helpers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bf276d42",
      "metadata": {},
      "outputs": [],
      "source": [
        "METRICS = [\"R2\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\", \"FitTimeSec\"]\n",
        "\n",
        "\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    return {\n",
        "        \"R2\": r2_score(y_true, y_pred),\n",
        "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
        "        \"MSE\": mse,\n",
        "        \"RMSE\": np.sqrt(mse),\n",
        "        \"MAPE\": mean_absolute_percentage_error(y_true, y_pred),\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate_models_for_embedding(df, embedding_name, builders, show_progress=True, progress=None):\n",
        "    X, y, base_cols, emb_cols = prepare_features(df)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    results = []\n",
        "    predictions = {}\n",
        "\n",
        "    for reg_name, build_model in builders.items():\n",
        "        if progress is not None:\n",
        "            progress[\"done\"] += 1\n",
        "            if show_progress:\n",
        "                print(f\"[{progress['done']}/{progress['total']}] {embedding_name} | {reg_name}\")\n",
        "        elif show_progress:\n",
        "            print(f\"{embedding_name} | {reg_name}\")\n",
        "\n",
        "        model = build_model(base_cols, emb_cols)\n",
        "        start = time.perf_counter()\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        fit_time = time.perf_counter() - start\n",
        "\n",
        "        metrics = compute_metrics(y_test, y_pred)\n",
        "        results.append({\n",
        "            \"embedding\": embedding_name,\n",
        "            \"regression\": reg_name,\n",
        "            **metrics,\n",
        "            \"FitTimeSec\": fit_time,\n",
        "        })\n",
        "        predictions[(embedding_name, reg_name)] = (y_test, y_pred)\n",
        "\n",
        "    return results, predictions\n",
        "\n",
        "\n",
        "def run_all_experiments(embedding_sources, builders, show_progress=True):\n",
        "    all_results = []\n",
        "    all_predictions = {}\n",
        "\n",
        "    progress = {\n",
        "        \"done\": 0,\n",
        "        \"total\": len(embedding_sources) * len(builders),\n",
        "    }\n",
        "    if show_progress:\n",
        "        print(f\"Total combinations: {progress['total']}\")\n",
        "\n",
        "    for embedding_name, embedding_path in embedding_sources.items():\n",
        "        if show_progress:\n",
        "            print(f\"Loading: {embedding_name}\")\n",
        "        df = load_embedding_dataset(embedding_path)\n",
        "        results, preds = evaluate_models_for_embedding(\n",
        "            df, embedding_name, builders, show_progress=show_progress, progress=progress\n",
        "        )\n",
        "        all_results.extend(results)\n",
        "        all_predictions.update(preds)\n",
        "\n",
        "    return pd.DataFrame(all_results), all_predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c15ff42",
      "metadata": {},
      "source": [
        "# Run the full experiment suite\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d750af9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total combinations: 25\n",
            "Loading: MiniLM-L6-v2\n",
            "[1/25] MiniLM-L6-v2 | Linear\n",
            "[2/25] MiniLM-L6-v2 | Ridge\n",
            "[3/25] MiniLM-L6-v2 | Lasso\n",
            "[4/25] MiniLM-L6-v2 | ElasticNet\n",
            "[5/25] MiniLM-L6-v2 | PolynomialRidge(deg2)\n",
            "Loading: mpnet-base-v2\n",
            "[6/25] mpnet-base-v2 | Linear\n",
            "[7/25] mpnet-base-v2 | Ridge\n",
            "[8/25] mpnet-base-v2 | Lasso\n",
            "[9/25] mpnet-base-v2 | ElasticNet\n",
            "[10/25] mpnet-base-v2 | PolynomialRidge(deg2)\n",
            "Loading: OpenAI-API\n",
            "[11/25] OpenAI-API | Linear\n",
            "[12/25] OpenAI-API | Ridge\n",
            "[13/25] OpenAI-API | Lasso\n"
          ]
        }
      ],
      "source": [
        "results_df, predictions_cache = run_all_experiments(\n",
        "    EMBEDDING_SOURCES_ACTIVE,\n",
        "    regression_builders_active,\n",
        "    show_progress=SHOW_PROGRESS,\n",
        ")\n",
        "\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc0f2f92",
      "metadata": {},
      "source": [
        "## Timing summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96bbf9cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Longest combinations (fit + predict)\n",
        "results_df.sort_values(\"FitTimeSec\", ascending=False).head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Metric tables (regressions x embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df[\"embedding\"] = pd.Categorical(\n",
        "    results_df[\"embedding\"], categories=embedding_order, ordered=True\n",
        ")\n",
        "results_df[\"regression\"] = pd.Categorical(\n",
        "    results_df[\"regression\"], categories=regression_order, ordered=True\n",
        ")\n",
        "\n",
        "metric_tables = {}\n",
        "for metric in METRICS:\n",
        "    table = (\n",
        "        results_df\n",
        "        .pivot(index=\"regression\", columns=\"embedding\", values=metric)\n",
        "        .reindex(index=regression_order, columns=embedding_order)\n",
        "    )\n",
        "    metric_tables[metric] = table\n",
        "\n",
        "metric_tables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Metric tables (one table per metric)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for metric in METRICS:\n",
        "    print(metric)\n",
        "    display(metric_tables[metric])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Boxplot grid (predicted vs actual, like in the reference)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_predicted_vs_actual_boxplot(ax, y_test, y_pred, title=None):\n",
        "    pred_vs_actual = pd.DataFrame({\n",
        "        \"points\": y_test,\n",
        "        \"predicted_points\": y_pred,\n",
        "    })\n",
        "\n",
        "    forced_points = list(range(80, 101))\n",
        "\n",
        "    data = [\n",
        "        pred_vs_actual.loc[pred_vs_actual[\"points\"] == p, \"predicted_points\"]\n",
        "        if (pred_vs_actual[\"points\"] == p).any()\n",
        "        else pd.Series(dtype=float)\n",
        "        for p in forced_points\n",
        "    ]\n",
        "\n",
        "    ax.boxplot(\n",
        "        data,\n",
        "        positions=range(1, len(forced_points) + 1),\n",
        "        widths=0.6,\n",
        "        showfliers=False,\n",
        "    )\n",
        "\n",
        "    x_pos = {p: i + 1 for i, p in enumerate(forced_points)}\n",
        "    xs = [x_pos[p] for p in forced_points]\n",
        "    ys = forced_points\n",
        "    ax.scatter(xs, ys, color=\"red\", zorder=3, label=\"y = x (80-100)\")\n",
        "\n",
        "    ax.set_xticks(range(1, len(forced_points) + 1))\n",
        "    ax.set_xticklabels(forced_points, rotation=90)\n",
        "    ax.set_yticks(forced_points)\n",
        "    ax.set_xlabel(\"Actual points\")\n",
        "    ax.set_ylabel(\"Predicted points\")\n",
        "    if title:\n",
        "        ax.set_title(title)\n",
        "\n",
        "\n",
        "def plot_boxplot_grid(predictions, regressions, embeddings):\n",
        "    n_rows = len(regressions)\n",
        "    n_cols = len(embeddings)\n",
        "\n",
        "    fig, axes = plt.subplots(\n",
        "        n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows), sharex=True, sharey=True\n",
        "    )\n",
        "\n",
        "    if n_rows == 1:\n",
        "        axes = np.array([axes])\n",
        "    if n_cols == 1:\n",
        "        axes = axes.reshape(n_rows, 1)\n",
        "\n",
        "    for i, reg in enumerate(regressions):\n",
        "        for j, emb in enumerate(embeddings):\n",
        "            ax = axes[i, j]\n",
        "            key = (emb, reg)\n",
        "            if key not in predictions:\n",
        "                ax.axis(\"off\")\n",
        "                continue\n",
        "\n",
        "            y_test, y_pred = predictions[key]\n",
        "            plot_predicted_vs_actual_boxplot(\n",
        "                ax,\n",
        "                y_test,\n",
        "                y_pred,\n",
        "                title=f\"{reg}\\n{emb}\",\n",
        "            )\n",
        "\n",
        "            if i < n_rows - 1:\n",
        "                ax.set_xlabel(\"\")\n",
        "                ax.set_xticklabels([])\n",
        "            if j > 0:\n",
        "                ax.set_ylabel(\"\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_boxplot_grid(predictions_cache, regression_order, embedding_order)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
