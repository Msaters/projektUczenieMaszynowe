{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1857b9ee",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33209848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"winemag-data-130k-v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e3068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_descriptions = df['description'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b18c8b",
   "metadata": {},
   "source": [
    "## Check how other models will be accurate with finding most simillar descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca41b77",
   "metadata": {},
   "source": [
    "# Sentence Transformers (SBERT) with models all-mpnet-base-v2, all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f683fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Milosz\\Desktop\\studia\\ml\\projekt\\projektUczenieMaszynowe\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m wine_descriptions = df[\u001b[33m'\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m'\u001b[39m].tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Milosz\\Desktop\\studia\\ml\\projekt\\projektUczenieMaszynowe\\.venv\\Lib\\site-packages\\sentence_transformers\\__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Milosz\\Desktop\\studia\\ml\\projekt\\projektUczenieMaszynowe\\.venv\\Lib\\site-packages\\sentence_transformers\\backend\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_optimized_onnx_model\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_static_quantized_openvino_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Milosz\\Desktop\\studia\\ml\\projekt\\projektUczenieMaszynowe\\.venv\\Lib\\site-packages\\sentence_transformers\\backend\\load.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _save_pretrained_wrapper, backend_should_export, backend_warn_to_save\n\u001b[32m     11\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Milosz\\Desktop\\studia\\ml\\projekt\\projektUczenieMaszynowe\\.venv\\Lib\\site-packages\\transformers\\__init__.py:958\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m    956\u001b[39m _import_structure = {k: \u001b[38;5;28mset\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _import_structure.items()}\n\u001b[32m--> \u001b[39m\u001b[32m958\u001b[39m import_structure = \u001b[43mdefine_import_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[34;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    959\u001b[39m import_structure[\u001b[38;5;28mfrozenset\u001b[39m({})].update(_import_structure)\n\u001b[32m    961\u001b[39m sys.modules[\u001b[34m__name__\u001b[39m] = _LazyModule(\n\u001b[32m    962\u001b[39m     \u001b[34m__name__\u001b[39m,\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[33m\"\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    966\u001b[39m     extra_objects={\u001b[33m\"\u001b[39m\u001b[33m__version__\u001b[39m\u001b[33m\"\u001b[39m: __version__},\n\u001b[32m    967\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Milosz\\Desktop\\studia\\ml\\projekt\\projektUczenieMaszynowe\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2867\u001b[39m, in \u001b[36mdefine_import_structure\u001b[39m\u001b[34m(module_path, prefix)\u001b[39m\n\u001b[32m   2843\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[32m   2844\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefine_import_structure\u001b[39m(module_path: \u001b[38;5;28mstr\u001b[39m, prefix: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> IMPORT_STRUCTURE_T:\n\u001b[32m   2845\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2846\u001b[39m \u001b[33;03m    This method takes a module_path as input and creates an import structure digestible by a _LazyModule.\u001b[39;00m\n\u001b[32m   2847\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2865\u001b[39m \u001b[33;03m    If `prefix` is not None, it will add that prefix to all keys in the returned dict.\u001b[39;00m\n\u001b[32m   2866\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2867\u001b[39m     import_structure = \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2868\u001b[39m     spread_dict = spread_import_structure(import_structure)\n\u001b[32m   2870\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Milosz\\Desktop\\studia\\ml\\projekt\\projektUczenieMaszynowe\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2580\u001b[39m, in \u001b[36mcreate_import_structure_from_path\u001b[39m\u001b[34m(module_path)\u001b[39m\n\u001b[32m   2578\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(module_path):\n\u001b[32m   2579\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m f != \u001b[33m\"\u001b[39m\u001b[33m__pycache__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m os.path.isdir(os.path.join(module_path, f)):\n\u001b[32m-> \u001b[39m\u001b[32m2580\u001b[39m         import_structure[f] = \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2582\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(os.path.join(directory, f)):\n\u001b[32m   2583\u001b[39m         adjacent_modules.append(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Milosz\\Desktop\\studia\\ml\\projekt\\projektUczenieMaszynowe\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2604\u001b[39m, in \u001b[36mcreate_import_structure_from_path\u001b[39m\u001b[34m(module_path)\u001b[39m\n\u001b[32m   2601\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_name.endswith(\u001b[33m\"\u001b[39m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   2602\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2604\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   2605\u001b[39m     file_content = f.read()\n\u001b[32m   2607\u001b[39m \u001b[38;5;66;03m# Remove the .py suffix\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:312\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, errors)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "wine_descriptions = df['description'].tolist()\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "embeddings = model.encode(wine_descriptions)\n",
    "embeddings = embeddings.astype(np.float32, copy=False)\n",
    "np.save(\"embeddings_all-mpnet-base-v2.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395b96df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Milosz\\Desktop\\studia\\ml\\projekt\\projektUczenieMaszynowe\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Milosz\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "wine_descriptions = df['description'].tolist()\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "embeddings = model.encode(wine_descriptions)\n",
    "embeddings = embeddings.astype(np.float32, copy=False)\n",
    "np.save(\"embeddings_all-mpnet-base-v2.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042d0c4b",
   "metadata": {},
   "source": [
    "# Open Ai API embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245c047e",
   "metadata": {},
   "source": [
    "Check how accurate will embeddings from LLM like Open Ai be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56336f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-2.15.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Using cached jiter-0.12.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\milosz\\desktop\\studia\\ml\\projekt\\projektuczeniemaszynowe\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\milosz\\desktop\\studia\\ml\\projekt\\projektuczeniemaszynowe\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\milosz\\desktop\\studia\\ml\\projekt\\projektuczeniemaszynowe\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\milosz\\desktop\\studia\\ml\\projekt\\projektuczeniemaszynowe\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.41.5-cp313-cp313-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\milosz\\desktop\\studia\\ml\\projekt\\projektuczeniemaszynowe\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-2.15.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.12.0-cp313-cp313-win_amd64.whl (204 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 22.1 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: typing-inspection, sniffio, pydantic-core, jiter, h11, distro, anyio, annotated-types, pydantic, httpcore, httpx, openai\n",
      "\n",
      "   ----------------------------------------  0/12 [typing-inspection]\n",
      "   --- ------------------------------------  1/12 [sniffio]\n",
      "   ------ ---------------------------------  2/12 [pydantic-core]\n",
      "   ------------- --------------------------  4/12 [h11]\n",
      "   ------------- --------------------------  4/12 [h11]\n",
      "   ------------- --------------------------  4/12 [h11]\n",
      "   ------------- --------------------------  4/12 [h11]\n",
      "   ------------- --------------------------  4/12 [h11]\n",
      "   ---------------- -----------------------  5/12 [distro]\n",
      "   ---------------- -----------------------  5/12 [distro]\n",
      "   -------------------- -------------------  6/12 [anyio]\n",
      "   -------------------- -------------------  6/12 [anyio]\n",
      "   -------------------- -------------------  6/12 [anyio]\n",
      "   -------------------- -------------------  6/12 [anyio]\n",
      "   -------------------- -------------------  6/12 [anyio]\n",
      "   -------------------- -------------------  6/12 [anyio]\n",
      "   -------------------- -------------------  6/12 [anyio]\n",
      "   -------------------- -------------------  6/12 [anyio]\n",
      "   -------------------- -------------------  6/12 [anyio]\n",
      "   -------------------- -------------------  6/12 [anyio]\n",
      "   -------------------- -------------------  6/12 [anyio]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [pydantic]\n",
      "   ------------------------------ ---------  9/12 [httpcore]\n",
      "   ------------------------------ ---------  9/12 [httpcore]\n",
      "   ------------------------------ ---------  9/12 [httpcore]\n",
      "   ------------------------------ ---------  9/12 [httpcore]\n",
      "   ------------------------------ ---------  9/12 [httpcore]\n",
      "   ------------------------------ ---------  9/12 [httpcore]\n",
      "   ------------------------------ ---------  9/12 [httpcore]\n",
      "   ------------------------------ ---------  9/12 [httpcore]\n",
      "   --------------------------------- ------ 10/12 [httpx]\n",
      "   --------------------------------- ------ 10/12 [httpx]\n",
      "   --------------------------------- ------ 10/12 [httpx]\n",
      "   --------------------------------- ------ 10/12 [httpx]\n",
      "   --------------------------------- ------ 10/12 [httpx]\n",
      "   --------------------------------- ------ 10/12 [httpx]\n",
      "   --------------------------------- ------ 10/12 [httpx]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ---------------------------------------- 12/12 [openai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.12.1 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.12.0 openai-2.15.0 pydantic-2.12.5 pydantic-core-2.41.5 sniffio-1.3.1 typing-inspection-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc47bbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings from wine_descriptions 129971\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Pasek postępu\n",
    "from private import API_KEY\n",
    "\n",
    "client = openai.OpenAI(api_key=API_KEY)\n",
    "MODEL = \"text-embedding-3-small\"\n",
    "BATCH_SIZE = 2000\n",
    "\n",
    "def get_embeddings_batched(texts, model=MODEL, batch_size=BATCH_SIZE):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        \n",
    "        try:\n",
    "            batch = [text.replace(\"\\n\", \" \") for text in batch]\n",
    "            \n",
    "            response = client.embeddings.create(input=batch, model=model)\n",
    "            \n",
    "            batch_embeddings = [data.embedding for data in response.data]\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Błąd przy paczce {i}: {e}\")\n",
    "            break\n",
    "\n",
    "    return all_embeddings\n",
    "\n",
    "print(f\"Embeddings from wine_descriptions {len(wine_descriptions)}\")\n",
    "embeddings_list = get_embeddings_batched(wine_descriptions)\n",
    "embeddings = np.array(embeddings_list).astype(np.float32, copy=False)\n",
    "np.save(\"embeddings_open_ai_api.npy\", embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e0ee94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"embeddings_open_ai_api.npy\", embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
