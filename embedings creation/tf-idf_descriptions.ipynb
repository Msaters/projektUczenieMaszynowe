{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c536a8",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1cb3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"winemag-data-130k-v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68473e1f",
   "metadata": {},
   "source": [
    "# Building Embedings from tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba96289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\",\n",
       " \"This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016.\",\n",
       " 'Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless_steel fermented.',\n",
       " 'Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of honey_drizzled guava and mango giving way to a slightly astringent, semidry finish.',\n",
       " \"Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal characteristics. Nonetheless, if you think of it as a pleasantly unfussy country wine, it's a good companion to a hearty winter stew.\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# changing '-' into '_' so that tfidf can capture these words\n",
    "wine_descriptions = df['description'].str.replace('-', '_', regex=False)\n",
    "display(wine_descriptions[:5].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677fc87",
   "metadata": {},
   "source": [
    "making stop words for tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba6bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "my_additional_stop_words = {'wine', 'drink', 'bottle', 'flavor', 'taste', 'like', 'nose', 'palate', 'finish', 'aroma', 'notes', 'note', 'vineyard', 'shows', 'alongside', 'offers', 'feels'}\n",
    "all_stop_words = list(ENGLISH_STOP_WORDS.union(my_additional_stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8709be29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wymiary macierzy TF-IDF: (129971, 44820)\n",
      "Wymiary embeddingów: (129971, 128)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from config import *\n",
    "\n",
    "# Tworzenie macierzy TF-IDF\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    min_df=MIN_WORD_OCCURENCE,\n",
    "    stop_words=all_stop_words,\n",
    "    max_df=0.3,\n",
    "    #token_pattern=r'(?u)\\b[\\w-]{2,}\\b'\n",
    "    ngram_range=(1, 2) # test z bigramami\n",
    ")\n",
    "display(MIN_WORD_OCCURENCE)\n",
    "tfidf_matrix = vectorizer.fit_transform(wine_descriptions)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "print(f\"Wymiary macierzy TF-IDF: {tfidf_matrix.shape}\")\n",
    "\n",
    "svd = TruncatedSVD(n_components=DIMENSIONS, random_state=RANDOM_STATE)\n",
    "embeddings = svd.fit_transform(tfidf_matrix)\n",
    "print(f\"Wymiary embeddingów: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fdc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '100', '15', '20', '2015', '2016', '2017', '2018', '2019',\n",
       "       '2020', '2022', '2025', 'accent', 'accented', 'accents', 'acidic',\n",
       "       'acidity', 'acids', 'add', 'adds', 'aftertaste', 'age', 'aged',\n",
       "       'aging', 'alcohol', 'almond', 'ample', 'anise', 'appeal',\n",
       "       'appealing', 'appellation', 'apple', 'apples', 'approachable',\n",
       "       'apricot', 'aromatic', 'astringent', 'attractive', 'backed',\n",
       "       'background', 'baked', 'baking', 'balance', 'balanced', 'barrel',\n",
       "       'bean', 'beautiful', 'beautifully', 'beef', 'berries'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017e042",
   "metadata": {},
   "source": [
    "# Saving Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b1ff8",
   "metadata": {},
   "source": [
    "## Slow way to save embeddings in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc3e273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svd_0</th>\n",
       "      <th>svd_1</th>\n",
       "      <th>svd_2</th>\n",
       "      <th>svd_3</th>\n",
       "      <th>svd_4</th>\n",
       "      <th>svd_5</th>\n",
       "      <th>svd_6</th>\n",
       "      <th>svd_7</th>\n",
       "      <th>svd_8</th>\n",
       "      <th>svd_9</th>\n",
       "      <th>...</th>\n",
       "      <th>svd_118</th>\n",
       "      <th>svd_119</th>\n",
       "      <th>svd_120</th>\n",
       "      <th>svd_121</th>\n",
       "      <th>svd_122</th>\n",
       "      <th>svd_123</th>\n",
       "      <th>svd_124</th>\n",
       "      <th>svd_125</th>\n",
       "      <th>svd_126</th>\n",
       "      <th>svd_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088711</td>\n",
       "      <td>-0.068887</td>\n",
       "      <td>-0.079682</td>\n",
       "      <td>-0.018129</td>\n",
       "      <td>-0.009653</td>\n",
       "      <td>-0.061104</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>-0.007166</td>\n",
       "      <td>-0.035704</td>\n",
       "      <td>0.049989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>-0.018292</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.022119</td>\n",
       "      <td>-0.020756</td>\n",
       "      <td>-0.007694</td>\n",
       "      <td>0.012150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.154284</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.158704</td>\n",
       "      <td>-0.078038</td>\n",
       "      <td>-0.090071</td>\n",
       "      <td>0.037020</td>\n",
       "      <td>0.055612</td>\n",
       "      <td>0.041271</td>\n",
       "      <td>-0.082306</td>\n",
       "      <td>-0.029474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001607</td>\n",
       "      <td>0.007284</td>\n",
       "      <td>-0.003020</td>\n",
       "      <td>-0.009733</td>\n",
       "      <td>-0.022264</td>\n",
       "      <td>-0.001541</td>\n",
       "      <td>0.029729</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>-0.003681</td>\n",
       "      <td>0.018890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065466</td>\n",
       "      <td>-0.094751</td>\n",
       "      <td>-0.029274</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.013507</td>\n",
       "      <td>-0.057787</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>0.060042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014752</td>\n",
       "      <td>0.023071</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.017879</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>-0.004585</td>\n",
       "      <td>-0.018330</td>\n",
       "      <td>0.028156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051657</td>\n",
       "      <td>-0.056965</td>\n",
       "      <td>-0.044632</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>-0.021166</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>-0.004410</td>\n",
       "      <td>-0.004401</td>\n",
       "      <td>-0.002667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001929</td>\n",
       "      <td>0.034152</td>\n",
       "      <td>-0.014469</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>-0.001094</td>\n",
       "      <td>-0.018169</td>\n",
       "      <td>-0.007891</td>\n",
       "      <td>-0.019679</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.008796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045352</td>\n",
       "      <td>0.010833</td>\n",
       "      <td>-0.007543</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.035781</td>\n",
       "      <td>0.040079</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>-0.043692</td>\n",
       "      <td>0.016170</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>-0.020048</td>\n",
       "      <td>0.027488</td>\n",
       "      <td>0.009093</td>\n",
       "      <td>-0.023184</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.011309</td>\n",
       "      <td>-0.011669</td>\n",
       "      <td>-0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      svd_0     svd_1     svd_2     svd_3     svd_4     svd_5     svd_6  \\\n",
       "0  0.088711 -0.068887 -0.079682 -0.018129 -0.009653 -0.061104  0.007078   \n",
       "1  0.154284  0.011388  0.158704 -0.078038 -0.090071  0.037020  0.055612   \n",
       "2  0.065466 -0.094751 -0.029274  0.011576 -0.006152  0.008905  0.013507   \n",
       "3  0.051657 -0.056965 -0.044632  0.016064  0.039736 -0.021166  0.016663   \n",
       "4  0.045352  0.010833 -0.007543  0.011982  0.035781  0.040079  0.049080   \n",
       "\n",
       "      svd_7     svd_8     svd_9  ...   svd_118   svd_119   svd_120   svd_121  \\\n",
       "0 -0.007166 -0.035704  0.049989  ...  0.006680  0.004052  0.009933  0.009689   \n",
       "1  0.041271 -0.082306 -0.029474  ... -0.001607  0.007284 -0.003020 -0.009733   \n",
       "2 -0.057787  0.006096  0.060042  ...  0.014752  0.023071  0.005033  0.010739   \n",
       "3 -0.004410 -0.004401 -0.002667  ... -0.001929  0.034152 -0.014469  0.001856   \n",
       "4 -0.043692  0.016170 -0.025930  ... -0.008363 -0.020048  0.027488  0.009093   \n",
       "\n",
       "    svd_122   svd_123   svd_124   svd_125   svd_126   svd_127  \n",
       "0 -0.018292  0.003419 -0.022119 -0.020756 -0.007694  0.012150  \n",
       "1 -0.022264 -0.001541  0.029729  0.006127 -0.003681  0.018890  \n",
       "2 -0.000433 -0.017879  0.004378 -0.004585 -0.018330  0.028156  \n",
       "3 -0.001094 -0.018169 -0.007891 -0.019679 -0.028118 -0.008796  \n",
       "4 -0.023184  0.012048  0.001023  0.011309 -0.011669 -0.000005  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_names = [f\"svd_{i}\" for i in range(DIMENSIONS)]\n",
    "df_embeddings = pd.DataFrame(embeddings, columns=col_names)\n",
    "df_embeddings = df_embeddings.astype('float32')\n",
    "df_embeddings.to_csv(\"embeddings_tf_idf_bigrams.csv\", index=False)\n",
    "\n",
    "display(df_embeddings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fdb72b",
   "metadata": {},
   "source": [
    "## Efficient way to safe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d40a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = embeddings.astype(np.float32, copy=False)\n",
    "np.save(\"embeddings_tf_idf_bigrams.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477ac27",
   "metadata": {},
   "source": [
    "## Comparing embedding file sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea37a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.npy 66.5 MB\n",
      "embeddings.csv 202.7 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import humanize\n",
    "\n",
    "for p in [\"embeddings.npy\", \"embeddings.csv\"]:\n",
    "    size = os.path.getsize(p)\n",
    "    print(p, humanize.naturalsize(size, binary=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb6371",
   "metadata": {},
   "source": [
    "# Concatenating with df and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac033ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = df_embeddings.reset_index(drop=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df_final = pd.concat([df, df_embeddings], axis=1)\n",
    "df_final.to_csv(EMBEDED_FILEPATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799472df",
   "metadata": {},
   "source": [
    "# Building Embedings from tf-idf using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157eb1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of SVD matrix: (129971, 128)\n"
     ]
    }
   ],
   "source": [
    "# Same thing but using pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with TfidfVectorizer and TruncatedSVD\n",
    "pipeline = Pipeline([\n",
    "  ('tfidf', TfidfVectorizer(max_features=50000, min_df=MIN_WORD_OCCURENCE, stop_words=all_stop_words, max_df=0.3, token_pattern=r'(?u)\\b[\\w-]{2,}\\b')),\n",
    "  ('pca', TruncatedSVD(n_components=DIMENSIONS, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Fit and transform the data using the pipeline\n",
    "svd_matrix = pipeline.fit_transform(wine_descriptions)\n",
    "print(\"Shape of SVD matrix:\", svd_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac836e19",
   "metadata": {},
   "source": [
    "# Look for most \"informative\" words in clusters using K-NN to find how well tf-idf dealt with noise data (e.g this, that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_top_words(k_final, num_words=10):\n",
    "    kmeans_final = KMeans(n_clusters=k_final, random_state=RANDOM_STATE, n_init=10)\n",
    "    predicted_labels = kmeans_final.fit_predict(embeddings)\n",
    "\n",
    "    # korzystamy z predicted labels do znalezienia słów w tym celu użyje TfidfVectorizer bo w tej interpretacji mam macierz słów do występowania ich\n",
    "    for i in range(k_final):\n",
    "        cluster_mask = (predicted_labels == i)\n",
    "        cluster_tfidf_matrix = tfidf_matrix[cluster_mask] # type: ignore\n",
    "\n",
    "        # licze centroid (licząc średni dla i-tego klastra w cluster_tfidf_matrix)\n",
    "        cluster_centroid = np.asarray(cluster_tfidf_matrix.mean(axis=0)).flatten()\n",
    "\n",
    "        top_indices = cluster_centroid.argsort()[-num_words:][::-1]\n",
    "        top_terms = [terms[idx] for idx in top_indices]\n",
    "\n",
    "        print(f\"\\nCluster {i}:\")\n",
    "        print(f\"  (Liczba dokumentów: {np.sum(cluster_mask)})\")\n",
    "        print(f\"  Top {num_words} terminów: {', '.join(top_terms)}\") # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091bd2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0:\n",
      "  (Liczba dokumentów: 5428)\n",
      "  Top 15 terminów: crisp, acidity, fruity, fresh, bright, ready, aftertaste, character, texture, lively, attractive, fruits, light, ripe, tight\n",
      "\n",
      "Cluster 1:\n",
      "  (Liczba dokumentów: 6019)\n",
      "  Top 15 terminów: cherry, tannins, red, berry, black, spice, clove, licorice, dried, leather, herb, firm, opens, raspberry, pepper\n",
      "\n",
      "Cluster 2:\n",
      "  (Liczba dokumentów: 5615)\n",
      "  Top 15 terminów: berry, plum, spice, red, wild, cherry, tannins, earthy, oak, good, spicy, tannic, fruits, bright, baked\n",
      "\n",
      "Cluster 3:\n",
      "  (Liczba dokumentów: 3796)\n",
      "  Top 15 terminów: bit, cherry, tannins, sweet, black, good, oak, red, dry, plum, green, spice, tart, raspberry, ripe\n",
      "\n",
      "Cluster 4:\n",
      "  (Liczba dokumentów: 8379)\n",
      "  Top 15 terminów: black, cherry, pepper, tannins, plum, dark, spice, chocolate, currant, licorice, red, ripe, dried, rich, bottling\n",
      "\n",
      "Cluster 5:\n",
      "  (Liczba dokumentów: 5276)\n",
      "  Top 15 terminów: soft, ripe, acidity, fruity, tannins, red, ready, fruits, texture, attractive, rounded, smooth, rich, juicy, character\n",
      "\n",
      "Cluster 6:\n",
      "  (Liczba dokumentów: 5737)\n",
      "  Top 15 terminów: lemon, lime, zest, apple, acidity, fresh, grapefruit, crisp, dry, citrus, white, freshness, pear, orange, bright\n",
      "\n",
      "Cluster 7:\n",
      "  (Liczba dokumentów: 4360)\n",
      "  Top 15 terminów: pinot, noir, cherry, silky, cola, raspberry, dry, acidity, cherries, rich, red, raspberries, years, chardonnay, oak\n",
      "\n",
      "Cluster 8:\n",
      "  (Liczba dokumentów: 6763)\n",
      "  Top 15 terminów: oak, new, french, vanilla, aged, cherry, tannins, months, rich, ripe, smoky, toast, toasty, acidity, black\n",
      "\n",
      "Cluster 9:\n",
      "  (Liczba dokumentów: 7201)\n",
      "  Top 15 terminów: blackberry, tannins, chocolate, ripe, cherry, black, dark, cassis, oak, rich, tannic, spice, jam, currant, plum\n",
      "\n",
      "Cluster 10:\n",
      "  (Liczba dokumentów: 5117)\n",
      "  Top 15 terminów: light, red, fresh, acidity, cherry, color, strawberry, texture, body, touch, raspberry, fruity, spice, bright, tart\n",
      "\n",
      "Cluster 11:\n",
      "  (Liczba dokumentów: 20157)\n",
      "  Top 15 terminów: cherry, acidity, dry, red, spice, raspberry, ripe, tannins, rich, fresh, good, tart, vanilla, texture, plum\n",
      "\n",
      "Cluster 12:\n",
      "  (Liczba dokumentów: 6292)\n",
      "  Top 15 terminów: apple, pear, green, acidity, fresh, ripe, lime, crisp, melon, yellow, dry, chardonnay, creamy, clean, peach\n",
      "\n",
      "Cluster 13:\n",
      "  (Liczba dokumentów: 5567)\n",
      "  Top 15 terminów: cabernet, sauvignon, merlot, blend, franc, verdot, petit, black, tannins, cherry, malbec, syrah, red, blackberry, spice\n",
      "\n",
      "Cluster 14:\n",
      "  (Liczba dokumentów: 7779)\n",
      "  Top 15 terminów: fruits, tannins, ripe, firm, rich, structure, acidity, dense, age, structured, black, character, juicy, concentrated, dark\n",
      "\n",
      "Cluster 15:\n",
      "  (Liczba dokumentów: 3935)\n",
      "  Top 15 terminów: wood, aging, fruits, ripe, rich, tannins, acidity, spice, character, black, years, age, juicy, structure, new\n",
      "\n",
      "Cluster 16:\n",
      "  (Liczba dokumentów: 6465)\n",
      "  Top 15 terminów: white, peach, acidity, melon, apricot, flower, yellow, fresh, pear, stone, mineral, creamy, crisp, almond, apple\n",
      "\n",
      "Cluster 17:\n",
      "  (Liczba dokumentów: 3772)\n",
      "  Top 15 terminów: herbal, plum, berry, green, earthy, tomato, spicy, cherry, raspberry, oak, tannins, tannic, red, lightly, slightly\n",
      "\n",
      "Cluster 18:\n",
      "  (Liczba dokumentów: 6265)\n",
      "  Top 15 terminów: citrus, fresh, acidity, apple, green, crisp, clean, dry, white, melon, stone, tropical, peach, fruits, grapefruit\n",
      "\n",
      "Cluster 19:\n",
      "  (Liczba dokumentów: 6048)\n",
      "  Top 15 terminów: sweet, acidity, vanilla, ripe, soft, honey, rich, cherry, simple, oak, orange, spice, pineapple, tastes, raspberry\n"
     ]
    }
   ],
   "source": [
    "get_top_words(20, 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
